seed: 42
n_timesteps: 1000000.0
policy: MlpPolicy
learning_rate: 0.00073
buffer_size: 200000
batch_size: 256
ent_coef: auto
gamma: 0.99
tau: 0.02
train_freq: 200
gradient_steps: 256
learning_starts: 500
use_sde_at_warmup: true
use_sde: true
sde_sample_freq: 16
policy_kwargs: dict(log_std_init=-3, net_arch=[256, 256])
